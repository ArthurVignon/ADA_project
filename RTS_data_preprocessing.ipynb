{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RTS Data Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tokenize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from itertools import islice\n",
    "\n",
    "\n",
    "BASE_PATH ='data/RTS_dataset_per_year/{}/{}'\n",
    "YEARS = np.arange(2010, 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next, we want to go year by year and find interviews that are with interviews of political parties\n",
    "    \n",
    "def read_in(party):\n",
    "    party_dict =[]\n",
    "    \n",
    "    for year in YEARS:\n",
    "        if os.path.exists(BASE_PATH.format(year, party)):\n",
    "            files = [f for f in os.listdir(BASE_PATH.format(year, party))]\n",
    "            for file in files:\n",
    "                with open(BASE_PATH.format(year, party)+\"/{}\".format(file), 'r', encoding='utf-8') as fp:\n",
    "                    dicts = json.load(fp)\n",
    "                    for entry in dicts['data']:\n",
    "                        if ('speechToTexts' or 'subTitles') in entry and ('publicationDate' in entry):\n",
    "                            if 'genres' in entry:\n",
    "                                if 'Interview' in entry['genres']:\n",
    "                                    party_dict.append(entry)\n",
    "                            if 'thematicThemes' in entry:\n",
    "                                for theme in entry['thematicThemes']:\n",
    "                                    if \"D√âBAT\" or \"POLITIQUE\" in theme:\n",
    "                                        party_dict.append(entry)\n",
    "                            if 'title' in entry:\n",
    "                                if \"d√©bat\" in entry['title']:\n",
    "                                    party_dict.append(entry)\n",
    "                            if 'thematicPersons' in entry:\n",
    "                                for person in entry['thematicPersons']:\n",
    "                                    if re.search(r'\\bUDC\\b|\\bVerts\\b|\\bPS\\b|\\bPDC\\b|\\bPLR\\b|\\bPES\\b', person):\n",
    "                                        party_dict.append(entry)\n",
    "\n",
    "    return party_dict\n",
    "\n",
    "#For each party, convert the json into dictionaries\n",
    "\n",
    "UDC_dictionary = read_in('UDC')\n",
    "PDC_dictionary = read_in('PDC')\n",
    "PS_dictionary = read_in('PS')\n",
    "PLR_dictionary = read_in('PLR')\n",
    "PES_dictionary = read_in('PES')\n",
    "PVL_dictionary = read_in('PVL')\n",
    "Verts_dictionary = read_in('Verts')\n",
    "Politique_dictionary = read_in('Politque')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "politique_dict =[]\n",
    "    \n",
    "for year in YEARS:\n",
    "    if os.path.exists(BASE_PATH.format(year, \"Politique\")):\n",
    "        files = [f for f in os.listdir(BASE_PATH.format(year, \"Politique\"))]\n",
    "        for file in files:\n",
    "            with open(BASE_PATH.format(year, \"politique\")+\"/{}\".format(file), 'r', encoding='utf-8') as fp:\n",
    "                dicts = json.load(fp)\n",
    "                for entry in dicts['data']:\n",
    "                    if ('speechToTexts' or 'subTitles') in entry and ('publicationDate' in entry):\n",
    "                        politique_dict.append(entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_party = pd.DataFrame.from_dict(politique_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, the json created by querying the RTS archive API for each of the party abbreviations was created into lists of dictionaries. However, it was noted that RTS does not often use the abbreviations for the PES and PVL parties and prefers to use the Verts and Verts lib√©reaux. Another query was made using the key word \"verts\" to find more broadcasts for these parties. Below these broadcasts were sorted into either verts or verts lib√©raux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading in the lists of dictionaries, each dictionary is converted to a pandas dataframe. During on our analysis we will look at either the \"speechToTexts\" or \"summary\" collumns in order to do some NLP to determine what the key issues each party were discussing and potentially their sentiment about these topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDC_pandas = pd.DataFrame.from_dict(UDC_dictionary)\n",
    "PDC_pandas = pd.DataFrame.from_dict(PDC_dictionary)\n",
    "PS_pandas = pd.DataFrame.from_dict(PS_dictionary)\n",
    "PLR_pandas = pd.DataFrame.from_dict(PLR_dictionary)\n",
    "PES_pandas = pd.DataFrame.from_dict(PES_dictionary)\n",
    "PVL_pandas = pd.DataFrame.from_dict(PVL_dictionary)\n",
    "Verts_pandas = pd.DataFrame.from_dict(Verts_dictionary)\n",
    "Politique_pandas = pd.DataFrame.from_dict(Politique_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next part is for processing the SpeechtoText portions of the interviews, first we analyse what percentage of our desired groups in fact have the SpeechtoText feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isabelle\\Anaconda3\\envs\\ada\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "party_pandas = [UDC_pandas, PDC_pandas, PS_pandas, PLR_pandas, PES_pandas, Verts_pandas, Politique_pandas]\n",
    "all_party = pd.concat(party_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we are cleaning up the data to get ready to make the topic model. A new attribute of year is added, subTitles and speechToTexts are combined with a preference to subtitles and then all duplicate entries are eliminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = all_party[\"publicationDate\"].str[:4]\n",
    "all_party['year'] = year\n",
    "all_party['contributor_count']= all_party.contributors.str.len()\n",
    "all_party['text'] = all_party.apply(lambda x: x['subTitles'] if x['speechToTexts'] == 'nan' else x['speechToTexts'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 500\n",
    "pd.set_option('display.max_rows', all_party.shape[0]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21257\n",
      "21014\n"
     ]
    }
   ],
   "source": [
    "print(len(all_party))\n",
    "all_party= all_party.drop_duplicates('internalArchiveId')\n",
    "print(len(all_party))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from above that the potentially useful columns to analyze the broadcasts would be the summary and speechToTexts. At first we will focus on the speechToTexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to look at the words used in the interviews, by both the interviewer and the interviewee using Robin's bag of words method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "str_YEARS = ['2019', '2018', '2017', '2016', '2015', '2014', '2013', '2012','2011','2010']\n",
    "\n",
    "\n",
    "def speech_to_words(speech, year=str_YEARS):\n",
    "    \"\"\"\n",
    "    Return a bag of word sorted by frequency\n",
    "    \n",
    "    lang: {'fr','de'}\n",
    "    username: {'PS Suisse', 'CVP PDC PPD PCD', 'UDC Suisse',\n",
    "       'Les VERTS suisses üåª', \"Vert'lib√©raux Suisse\", 'PLR Suisse'}\n",
    "    year: default = [2019, 2018, 2017, 2016, 2015, 2014, 2013, 2012, 2011, 2010]\n",
    "    \n",
    "    \"\"\"\n",
    "    speech_copy = speech.copy()\n",
    "    speech_copy = speech_copy[speech_copy['year'].isin(year)]\n",
    "    speech_copy = speech_copy[\"text\"].astype(str).str.lower()\n",
    "    \n",
    "    for text in speech_copy:\n",
    "        yield(gensim.utils.simple_preprocess(str(text), deacc=True))  # deacc=True removes punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_fr = stopwords.words('french')\n",
    "stopwords_fr.extend(['nlocuteur'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigation for using Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words = list(speech_to_words(all_party))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram model\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=75) # higher threshold fewer phrases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faster way to get a sentence clubbed as a bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove stop words, make birgams and lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['volet', 'serie', 'apparaitre', 'partir', 'janvier', 'janvier', 'fois', 'marche', 'energie', 'longuement', 'evoque', 'augmentation', 'factur', 'electricite', 'semaine', 'emission', 'aller', 'energie', 'electriqu', 'nouveau', 'disposition', 'prevue', 'neh', 'bien', 'demain', 'loi', 'energie', 'vigueur', 'bien', 'serie', 'changement', 'tre', 'visible', 'alors', 'penche', 'plus', 'concerner', 'auditeur', 'savoir', 'nouveau', 'politique', 'concerner', 'retribution', 'prix_coutant', 'courir', 'injecte', 'alors', 'porte_parole', 'office_federal', 'energie', 'explique', 'modification', 'loi', 'energie', 'mt', 'essentiel', 'augmentation', 'moyen', 'promotion', 'courir', 'electriqu', 'origine', 'renouvelable', 'fameux', 'retribution', 'prix_coutant', 'courir', 'injecte', 'issu', 'taxe', 'maximal', 'consommateur', 'pay', 'passer', 'effet', 'centime', 'maximum', 'partir', 'centime', 'maximum', 'hui', 'alors', 'environ', 'million', 'franc', 'fonds', 'hui', 'henry', 'manqu', 'bout', 'exposer', 'retribution', 'prix_coutant', 'energie', 'particulier', 'petit', 'entreprise', 'produire', 'systeme', 'record', 'systeme', 'tre', 'bien', 'donc', 'role', 'produit', 'cite', 'trop', 'donc', 'redistribution', 'distribution', 'voiler', 'donc', 'touch', 'argent', 'exactement', 'tre', 'bien', 'donc', 'loi', 'vigueur', 'partir', 'demain', 'aller', 'sentir', 'effet', 'immediatemer', 'non', 'effectivement', 'important', 'bon', 'direction', 'reproch', 'longtemps', 'confederation', 'faire', 'assez', 'encourager', 'installation', 'fameux', 'panneaux_solaire', 'm', 'rupture', 'bon', 'moment', 'lancer', 'projet', 'installation', 'photovoltaiqu', 'nmai', 'dirai', 'toujours', 'bon', 'moment', 'prendre', 'retard', 'niveau', 'suisse', 'falloir', 'moment', 'rattraper', 'change', 'part', 'maximal', 'fonds', 'photovoltaiqu', 'passer', 'pourcent', 'permettre', 'rattraper', 'retard', 'parallele', 'augmentation', 'fonds', 'detecter', 'donc', 'departement', 'environnement', 'transport', 'communication', 'decid', 'janvier', 'baisser', 'pourcent', 'taux', 'courir', 'photovoltaiqu', 'raison', 'tre', 'simple', 'explique', 'mathieu', 'parle', 'baisse', 'uniquement', 'technologie', 'photovoltaiqu', 'taux', 'baisser', 'effectivement', 'pourcent', 'moyen', 'janvier', 'raison', 'tre', 'simple', 'installation', 'devenir', 'meilleur', 'marche', 'amelioration', 'technologie', 'baiss', 'prix', 'production', 'part', 'maximal', 'fonds', 'photovoltaiqu', 'aller', 'augmenter', 'pourcent', 'ca', 'aller', 'permettre', 'repondre', 'plus', 'demande', 'mt', 'alors', 'aller', 'permettre', 'repondre', 'implicitement', 'augmenter', 'capacite', 'annuel', 'installations_photovoltaique', 'megawatt', 'hui', 'megawatt', 'partir', 'alors', 'liste', 'attent', 'actuel', 'projet', 'annonce', 'commencer', 'reduite', 'supprimer', 'parle', 'chose', 'bien', 'hein', 'faire', 'injecter', 'electricite', 'fabriqu', 'electricite', 'aller', 'donner', 'aller', 'diminuer', 'oui', 'anne', 'prochain', 'revanche', 'incitation', 'concerne', 'installation', 'concerne', 'projet', 'donc', 'ca', 'nouveau', 'projet', 'partir', 'exemple', 'accord', 'm', 'nmai', 'ca', 'dire', 'aussi', 'autre', 'point', 'installer', 'materiel', 'electriqu', 'toit', 'maison', 'bourse', 'faire', 'plus', 'grand', 'exactement', 'accord', 'bien', 'compris', 'donc', 'question', 'lumiere', 'reponse', 'donne', 'ca', 'valoir', 'peine', 'prevoir', 'installation', 'panneaux_solaire', 'oui', 'dire', 'annonce', 'maintenant', 'servi', 'donc', 'di', 'cer', 'mois', 'janvier', 'sans_doute', 'encore', 'patienter', 'moment', 'clair', 'premier', 'inscrit', 'premier', 'servi', 'donc', 'oui', 'interesser', 'lancer', 'maintenant', 'savoir', 'attente', 'pouvoir', 'nouveau', 'loi', 'contenir', 'autre', 'disposition', 'interesser', 'grand', 'public', 'oui', 'meme', 'aller', 'parler', 'chose', 'tre', 'quand', 'parle', 'certificat', 'energetiqu', 'batiment', 'ete', 'faire', 'politique', 'application', 'certificat', 'base', 'mem', 'voiture', 'cantonal', 'harmonise', 'niveau', 'federal', 'certificat', 'unique', 'voila', 'principe', 'federal', 'application', 'canton', 'exactement', 'ecoute', 'propos', 'explication', 'faire', 'loi', 'necessaire', 'etablissement', 'certificat', 'energetiqu', 'batiment', 'uniforme', 'jusqu', 'eter', 'uniformiser', 'canton', 'faire', 'peu', 'nil', 'projet', 'certificat', 'energetiqu', 'cantonal', 'maintenant', 'demande', 'certificat', 'uniforme', 'tout', 'nconcernant', 'certificat', 'facultatif', 'canton', 'utiliser', 'facultatif', 'effectivement', 'canton', 'libre', 'rendre', 'norme', 'contraignant', 'actuellement', 'canton', 'obligatoire', 'faire', 'instant', 'obtention', 'certificat', 'batiment', 'fruit', 'faire', 'individuel', 'faire', 'site', 'point', 'assez', 'gratuit', 'sinon', 'etude', 'plus', 'falloir', 'faire', 'appel', 'expert', 'prix', 'varie', 'fonction', 'batiment', 'certificat', 'alors', 'accompagne', 'rapport', 'averer', 'tre', 'utile', 'precis', 'meme', 'etayer', 'accompagne', 'rapport', 'expert', 'tre', 'utile', 'personne', 'justement', 'souhaite', 'exemple', 'renover', 'maison', 'voir', 'non', 'seulement', 'etat', 'maison', 'egalement', 'commencer', 'lorsqu', 'vouloir', 'renovation', 'absolument', 'certificat', 'subvention', 'renovation', 'programme', 'national', 'batiment', 'falloir', 'absolument', 'certificat', 'certificat', 'aussi', 'utile', 'lors', 'vente', 'batiment', 'chose', 'tre', 'important', 'jour', 'valeur', 'immeuble', 'enfin', 'dernier', 'point', 'concerner', 'loi', 'prevoit', 'favoriser', 'diffusion', 'information', 'aupre', 'public', 'valoriser', 'potentiel', 'batiment', 'hic', 'taille', 'loi', 'prevoit', 'budget', 'encore', 'vote', 'eter', 'dernier', 'episode', 'serie', 'porter', 'un', 'changement', 'attendre', 'million', 'souhaite', 'excellent', 'bon', 'fete', 'reveillon', 'soir', 'dire', 'sai', 'encore', 'sai', 'encore', 'reflechir', 'faire', 'organiser', 'chose', 'ben', 'aller', 'souhaite', 'excedent', 'eme']]\n"
     ]
    }
   ],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stopwords_fr] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n",
    "\n",
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'fr_core_news_md' model\n",
    "nlp = spacy.load('fr_core_news_md', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 2), (1, 2), (2, 2), (3, 1), (4, 1), (5, 9), (6, 6), (7, 1), (8, 1), (9, 2), (10, 1), (11, 1), (12, 1), (13, 2), (14, 1), (15, 2), (16, 1), (17, 1), (18, 1), (19, 1), (20, 3), (21, 2), (22, 1), (23, 2), (24, 2), (25, 1), (26, 1), (27, 1), (28, 2), (29, 1), (30, 7), (31, 1), (32, 6), (33, 4), (34, 1), (35, 1), (36, 1), (37, 4), (38, 5), (39, 2), (40, 1), (41, 2), (42, 1), (43, 12), (44, 1), (45, 2), (46, 4), (47, 1), (48, 1), (49, 2), (50, 1), (51, 1), (52, 2), (53, 3), (54, 1), (55, 1), (56, 1), (57, 1), (58, 4), (59, 1), (60, 2), (61, 2), (62, 1), (63, 2), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 3), (71, 1), (72, 2), (73, 1), (74, 9), (75, 1), (76, 1), (77, 1), (78, 3), (79, 2), (80, 1), (81, 3), (82, 3), (83, 1), (84, 1), (85, 4), (86, 1), (87, 3), (88, 6), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 2), (100, 1), (101, 1), (102, 3), (103, 1), (104, 1), (105, 2), (106, 2), (107, 1), (108, 2), (109, 1), (110, 1), (111, 1), (112, 2), (113, 11), (114, 3), (115, 2), (116, 1), (117, 2), (118, 1), (119, 1), (120, 1), (121, 4), (122, 1), (123, 1), (124, 2), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 3), (131, 1), (132, 1), (133, 1), (134, 2), (135, 1), (136, 1), (137, 1), (138, 2), (139, 1), (140, 1), (141, 5), (142, 1), (143, 1), (144, 1), (145, 2), (146, 1), (147, 5), (148, 1), (149, 1), (150, 1), (151, 2), (152, 1), (153, 1), (154, 7), (155, 1), (156, 1), (157, 1), (158, 1), (159, 1), (160, 2), (161, 3), (162, 3), (163, 1), (164, 2), (165, 1), (166, 1), (167, 3), (168, 2), (169, 2), (170, 1), (171, 1), (172, 2), (173, 2), (174, 1), (175, 1), (176, 4), (177, 2), (178, 2), (179, 1), (180, 1), (181, 1), (182, 1), (183, 1), (184, 2), (185, 2), (186, 2), (187, 1), (188, 4), (189, 1), (190, 1), (191, 1), (192, 1), (193, 1), (194, 4), (195, 2), (196, 1), (197, 3), (198, 1), (199, 2), (200, 1), (201, 5), (202, 2), (203, 1), (204, 1), (205, 1), (206, 1), (207, 3), (208, 1), (209, 1), (210, 1), (211, 5), (212, 4), (213, 3), (214, 2), (215, 1), (216, 1), (217, 1), (218, 4), (219, 1), (220, 1), (221, 2), (222, 1), (223, 1), (224, 2), (225, 1), (226, 1), (227, 2), (228, 3), (229, 1), (230, 1), (231, 1), (232, 1), (233, 1), (234, 5), (235, 1), (236, 1), (237, 2), (238, 1), (239, 1), (240, 2), (241, 2), (242, 2), (243, 1), (244, 1), (245, 1), (246, 1), (247, 1), (248, 1), (249, 2), (250, 1), (251, 2), (252, 1), (253, 1), (254, 2), (255, 3), (256, 1), (257, 1), (258, 1), (259, 1), (260, 2), (261, 1), (262, 2), (263, 1), (264, 1), (265, 3), (266, 2), (267, 1), (268, 2), (269, 1), (270, 1), (271, 1), (272, 3), (273, 1), (274, 1), (275, 1), (276, 2), (277, 1), (278, 2), (279, 1), (280, 2), (281, 1), (282, 1), (283, 1), (284, 1), (285, 1), (286, 9), (287, 1), (288, 1), (289, 2), (290, 1), (291, 1), (292, 1), (293, 3), (294, 1), (295, 1), (296, 1), (297, 1), (298, 1), (299, 1), (300, 2), (301, 1), (302, 1), (303, 1), (304, 1), (305, 1), (306, 1), (307, 1), (308, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of the topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.031*\"film\" + 0.019*\"musiqu\" + 0.017*\"aussi\" + 0.014*\"spectacle\" + '\n",
      "  '0.013*\"faire\" + 0.012*\"tre\" + 0.012*\"eter\" + 0.010*\"festival\" + '\n",
      "  '0.010*\"donc\" + 0.008*\"artiste\"'),\n",
      " (1,\n",
      "  '0.031*\"politique\" + 0.028*\"mouvement\" + 0.021*\"eter\" + 0.018*\"pays\" + '\n",
      "  '0.013*\"manifestation\" + 0.012*\"peuple\" + 0.009*\"rue\" + 0.009*\"gauche\" + '\n",
      "  '0.008*\"gouvernement\" + 0.008*\"partir\"'),\n",
      " (2,\n",
      "  '0.040*\"faire\" + 0.022*\"dire\" + 0.021*\"aller\" + 0.017*\"oui\" + 0.016*\"plus\" + '\n",
      "  '0.016*\"tout\" + 0.015*\"eter\" + 0.015*\"non\" + 0.015*\"bien\" + 0.015*\"meme\"'),\n",
      " (3,\n",
      "  '0.035*\"franc\" + 0.028*\"plus\" + 0.018*\"pourcent\" + 0.017*\"sant\" + '\n",
      "  '0.016*\"retraite\" + 0.015*\"payer\" + 0.013*\"medecin\" + 0.013*\"patient\" + '\n",
      "  '0.012*\"prix\" + 0.011*\"cout\"'),\n",
      " (4,\n",
      "  '0.034*\"livre\" + 0.023*\"histoire\" + 0.018*\"eter\" + 0.012*\"mot\" + '\n",
      "  '0.011*\"dire\" + 0.010*\"texte\" + 0.009*\"auteur\" + 0.009*\"vie\" + 0.009*\"roman\" '\n",
      "  '+ 0.007*\"homme\"'),\n",
      " (5,\n",
      "  '0.022*\"affaire\" + 0.013*\"loi\" + 0.013*\"droit\" + 0.012*\"etat\" + '\n",
      "  '0.011*\"justice\" + 0.011*\"cas\" + 0.010*\"tribunal\" + 0.010*\"faire\" + '\n",
      "  '0.009*\"commission\" + 0.009*\"decision\"'),\n",
      " (6,\n",
      "  '0.051*\"accord\" + 0.025*\"pays\" + 0.019*\"mt\" + 0.018*\"gouvernement\" + '\n",
      "  '0.016*\"politique\" + 0.016*\"europeenne\" + 0.013*\"ministre\" + 0.013*\"droit\" + '\n",
      "  '0.012*\"britannique\" + 0.011*\"etat\"'),\n",
      " (7,\n",
      "  '0.037*\"pays\" + 0.029*\"americain\" + 0.023*\"chinois\" + 0.018*\"guerre\" + '\n",
      "  '0.014*\"russe\" + 0.013*\"syrie\" + 0.012*\"etats_uni\" + 0.012*\"international\" + '\n",
      "  '0.012*\"etat\" + 0.012*\"militaire\"'),\n",
      " (8,\n",
      "  '0.084*\"femme\" + 0.034*\"enfant\" + 0.034*\"jeune\" + 0.026*\"homme\" + 0.021*\"an\" '\n",
      "  '+ 0.017*\"fille\" + 0.017*\"vie\" + 0.015*\"famille\" + 0.013*\"parent\" + '\n",
      "  '0.013*\"ecole\"'),\n",
      " (9,\n",
      "  '0.028*\"politique\" + 0.018*\"partir\" + 0.017*\"parti\" + 0.013*\"candidat\" + '\n",
      "  '0.013*\"gauche\" + 0.013*\"aussi\" + 0.013*\"socialiste\" + 0.011*\"vote\" + '\n",
      "  '0.011*\"campagne\" + 0.011*\"elu\"'),\n",
      " (10,\n",
      "  '0.035*\"presse\" + 0.028*\"journal\" + 0.024*\"journaliste\" + 0.023*\"matin\" + '\n",
      "  '0.018*\"information\" + 0.017*\"media\" + 0.017*\"donnee\" + 0.016*\"internet\" + '\n",
      "  '0.014*\"facebook\" + 0.011*\"public\"'),\n",
      " (11,\n",
      "  '0.061*\"eglise\" + 0.059*\"religieux\" + 0.053*\"religion\" + 0.040*\"musulman\" + '\n",
      "  '0.035*\"islam\" + 0.022*\"arabe\" + 0.022*\"catholique\" + 0.020*\"juif\" + '\n",
      "  '0.016*\"homosexuel\" + 0.016*\"chretien\"'),\n",
      " (12,\n",
      "  '0.016*\"plus\" + 0.012*\"degre\" + 0.012*\"encore\" + 0.012*\"suisse\" + '\n",
      "  '0.011*\"soir\" + 0.011*\"aller\" + 0.011*\"heure\" + 0.011*\"demain\" + '\n",
      "  '0.010*\"apre\" + 0.010*\"tout\"'),\n",
      " (13,\n",
      "  '0.039*\"violence\" + 0.035*\"police\" + 0.025*\"arme\" + 0.021*\"personne\" + '\n",
      "  '0.020*\"armee\" + 0.019*\"policier\" + 0.016*\"avion\" + 0.015*\"victime\" + '\n",
      "  '0.015*\"mort\" + 0.011*\"securite\"'),\n",
      " (14,\n",
      "  '0.190*\"suisse\" + 0.026*\"equipe\" + 0.024*\"football\" + 0.023*\"match\" + '\n",
      "  '0.022*\"sport\" + 0.020*\"allemand\" + 0.020*\"pays\" + 0.018*\"club\" + '\n",
      "  '0.018*\"joueur\" + 0.014*\"aussi\"'),\n",
      " (15,\n",
      "  '0.026*\"ville\" + 0.020*\"plus\" + 0.013*\"ici\" + 0.009*\"grand\" + 0.007*\"aussi\" '\n",
      "  '+ 0.007*\"faire\" + 0.007*\"petit\" + 0.007*\"net\" + 0.007*\"voir\" + 0.006*\"m\"'),\n",
      " (16,\n",
      "  '0.017*\"plus\" + 0.017*\"produire\" + 0.014*\"environnement\" + 0.013*\"climat\" + '\n",
      "  '0.012*\"animal\" + 0.012*\"produit\" + 0.011*\"scientifique\" + '\n",
      "  '0.010*\"agriculture\" + 0.010*\"production\" + 0.009*\"consommateur\"'),\n",
      " (17,\n",
      "  '0.027*\"suisse\" + 0.018*\"faire\" + 0.015*\"aussi\" + 0.015*\"plus\" + '\n",
      "  '0.014*\"falloir\" + 0.012*\"aller\" + 0.011*\"entreprise\" + 0.009*\"hui\" + '\n",
      "  '0.009*\"projet\" + 0.008*\"travail\"'),\n",
      " (18,\n",
      "  '0.020*\"plus\" + 0.015*\"hier\" + 0.013*\"nouveau\" + 0.010*\"an\" + 0.010*\"apre\" + '\n",
      "  '0.009*\"faire\" + 0.008*\"dernier\" + 0.008*\"heure\" + 0.008*\"encore\" + '\n",
      "  '0.007*\"premier\"'),\n",
      " (19,\n",
      "  '0.028*\"donc\" + 0.028*\"dire\" + 0.027*\"faire\" + 0.021*\"aussi\" + 0.019*\"plus\" '\n",
      "  '+ 0.018*\"tre\" + 0.013*\"meme\" + 0.012*\"bien\" + 0.012*\"peu\" + 0.012*\"aller\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/models/RTS_models/all_politique.state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\ada\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, fname_or_handle, separately, sep_limit, ignore, pickle_protocol)\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 692\u001b[1;33m             \u001b[0m_pickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname_or_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    693\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"saved %s object\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: file must have a 'write' attribute",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-820aff93608e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Saving the politique only model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlda_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/models/RTS_models/all_politique'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\ada\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, fname, ignore, separately, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1569\u001b[0m         \"\"\"\n\u001b[0;32m   1570\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1571\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msmart_extension\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'.state'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1572\u001b[0m         \u001b[1;31m# Save the dictionary separately if not in 'ignore'.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1573\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'id2word'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mignore\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ada\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, fname_or_handle, separately, sep_limit, ignore, pickle_protocol)\u001b[0m\n\u001b[0;32m    693\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"saved %s object\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# `fname_or_handle` does not have write attribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 695\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_smart_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname_or_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseparately\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep_limit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ada\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36m_smart_save\u001b[1;34m(self, fname, separately, sep_limit, ignore, pickle_protocol)\u001b[0m\n\u001b[0;32m    547\u001b[0m                                        compress, subname)\n\u001b[0;32m    548\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m             \u001b[0mpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;31m# restore attribs handled specially\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ada\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36mpickle\u001b[1;34m(obj, fname, protocol)\u001b[0m\n\u001b[0;32m   1361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m     \"\"\"\n\u001b[1;32m-> 1363\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfout\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 'b' for binary, needed on Windows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1364\u001b[0m         \u001b[0m_pickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ada\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, transport_params)\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m         \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m     )\n\u001b[0;32m    310\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ada\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[1;34m(uri, mode, ignore_ext, buffering, encoding, errors)\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPY3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mopen_kwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/models/RTS_models/all_politique.state'"
     ]
    }
   ],
   "source": [
    "#Saving the politique only model\n",
    "lda_model.save('/models/RTS_models/all_politique.state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -8.846336314474296\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-eacbdc545be3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Compute Coherence Score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcoherence_model_lda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCoherenceModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_lemmatized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoherence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c_v'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mcoherence_lda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoherence_model_lda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_coherence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nCoherence Score: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoherence_lda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ada\\lib\\site-packages\\gensim\\models\\coherencemodel.py\u001b[0m in \u001b[0;36mget_coherence\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m         \"\"\"\n\u001b[1;32m--> 609\u001b[1;33m         \u001b[0mconfirmed_measures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_coherence_per_topic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    610\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maggregate_measures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfirmed_measures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ada\\lib\\site-packages\\gensim\\models\\coherencemodel.py\u001b[0m in \u001b[0;36mget_coherence_per_topic\u001b[1;34m(self, segmented_topics, with_std, with_support)\u001b[0m\n\u001b[0;32m    567\u001b[0m             \u001b[0msegmented_topics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeasure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtopics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accumulator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 569\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimate_probabilities\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msegmented_topics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_std\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwith_std\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwith_support\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwith_support\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ada\\lib\\site-packages\\gensim\\models\\coherencemodel.py\u001b[0m in \u001b[0;36mestimate_probabilities\u001b[1;34m(self, segmented_topics)\u001b[0m\n\u001b[0;32m    539\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeyed_vectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accumulator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeasure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accumulator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ada\\lib\\site-packages\\gensim\\topic_coherence\\probability_estimation.py\u001b[0m in \u001b[0;36mp_boolean_sliding_window\u001b[1;34m(texts, segmented_topics, dictionary, window_size, processes)\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[0maccumulator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallelWordOccurrenceAccumulator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"using %s to estimate probabilities from sliding windows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccumulator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0maccumulator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ada\\lib\\site-packages\\gensim\\topic_coherence\\text_analysis.py\u001b[0m in \u001b[0;36maccumulate\u001b[1;34m(self, texts, window_size)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0maccumulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m         \u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_q\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_q\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_workers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue_all_texts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_q\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ada\\lib\\site-packages\\gensim\\topic_coherence\\text_analysis.py\u001b[0m in \u001b[0;36mstart_workers\u001b[1;34m(self, window_size)\u001b[0m\n\u001b[0;32m    476\u001b[0m             \u001b[0maccumulator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPatchedWordOccurrenceAccumulator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelevant_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[0mworker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAccumulatingWorker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_q\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_q\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccumulator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 478\u001b[1;33m             \u001b[0mworker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    479\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ada\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ada\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ada\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ada\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ada\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'C:\\Users\\Isabelle\\Downloads\\mallet-2.0.8\\mallet-2.0.8\\bin\\mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input C:\\Users\\Isabelle\\AppData\\Local\\Temp\\d07ed4_corpus.txt --output C:\\Users\\Isabelle\\AppData\\Local\\Temp\\d07ed4_corpus.mallet' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-293e5d12fd52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmallet_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'C:\\\\Users\\\\Isabelle\\\\Downloads\\\\mallet-2.0.8\\\\mallet-2.0.8\\\\bin\\\\mallet'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mldamallet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLdaMallet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmallet_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# update this path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ada\\lib\\site-packages\\gensim\\models\\wrappers\\ldamallet.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, mallet_path, corpus, num_topics, alpha, id2word, workers, prefix, optimize_interval, iterations, topic_threshold, random_seed)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_seed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfinferencer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ada\\lib\\site-packages\\gensim\\models\\wrappers\\ldamallet.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, corpus)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m         \"\"\"\n\u001b[1;32m--> 272\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m         \u001b[0mcmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmallet_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' train-topics --input %s --num-topics %s  --alpha %s --optimize-interval %s '\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m             \u001b[1;34m'--num-threads %s --output-state %s --output-doc-topics %s --output-topic-keys %s '\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ada\\lib\\site-packages\\gensim\\models\\wrappers\\ldamallet.py\u001b[0m in \u001b[0;36mconvert_input\u001b[1;34m(self, corpus, infer, serialize_corpus)\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mcmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcmd\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfcorpustxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfcorpusmallet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"converting temporary corpus to MALLET format with %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m         \u001b[0mcheck_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ada\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36mcheck_output\u001b[1;34m(stdout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m   1916\u001b[0m             \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1917\u001b[0m             \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1919\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command 'C:\\Users\\Isabelle\\Downloads\\mallet-2.0.8\\mallet-2.0.8\\bin\\mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input C:\\Users\\Isabelle\\AppData\\Local\\Temp\\d07ed4_corpus.txt --output C:\\Users\\Isabelle\\AppData\\Local\\Temp\\d07ed4_corpus.mallet' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "#TODO Look into Mallet model, apparently it gets better topics but there are several\n",
    "#download steps\n",
    "\n",
    "import os \n",
    "from gensim.models.wrappers import LdaMallet\n",
    "os.environ.update({'MALLET_HOME': r'C:\\\\Users\\\\Isabelle\\\\Downloads\\\\mallet-2.0.8\\\\mallet-2.0.8\\\\bin\\\\mallet'})\n",
    "mallet_path = 'C:\\\\Users\\\\Isabelle\\\\Downloads\\\\mallet-2.0.8\\\\mallet-2.0.8\\\\bin\\\\mallet'\n",
    "\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word) # update this path\n",
    "\n",
    "\n",
    "# Show Topics\n",
    "pprint(ldamallet.show_topics(formatted=False))\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to find the optimal number of topics by looking at their coherence values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        #model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=num_topics, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=50,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "        model_list.append(lda_model)\n",
    "        coherencemodel = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values\n",
    "# Can take a long time to run.\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=2, limit=40, step=6)\n",
    "# Show graph\n",
    "limit=40; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Topics = 2  has Coherence Value of 0.3056\n",
      "Num Topics = 8  has Coherence Value of 0.2802\n",
      "Num Topics = 14  has Coherence Value of 0.3199\n",
      "Num Topics = 20  has Coherence Value of 0.3056\n",
      "Num Topics = 26  has Coherence Value of 0.254\n",
      "Num Topics = 32  has Coherence Value of 0.2496\n",
      "Num Topics = 38  has Coherence Value of 0.2639\n"
     ]
    }
   ],
   "source": [
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.029*\"faire\" + 0.022*\"dire\" + 0.017*\"plus\" + 0.015*\"eter\" + 0.013*\"aussi\" '\n",
      "  '+ 0.012*\"donc\" + 0.012*\"bien\" + 0.012*\"meme\" + 0.011*\"tre\" + 0.010*\"oui\"'),\n",
      " (1,\n",
      "  '0.017*\"faire\" + 0.014*\"aller\" + 0.013*\"aussi\" + 0.013*\"dire\" + 0.013*\"plus\" '\n",
      "  '+ 0.011*\"tre\" + 0.010*\"donc\" + 0.010*\"politique\" + 0.009*\"bien\" + '\n",
      "  '0.008*\"peu\"'),\n",
      " (2,\n",
      "  '0.023*\"faire\" + 0.020*\"plus\" + 0.015*\"dire\" + 0.015*\"aller\" + '\n",
      "  '0.012*\"falloir\" + 0.011*\"aussi\" + 0.011*\"donc\" + 0.008*\"projet\" + '\n",
      "  '0.008*\"franc\" + 0.008*\"bien\"'),\n",
      " (3,\n",
      "  '0.021*\"faire\" + 0.018*\"dire\" + 0.011*\"suisse\" + 0.009*\"donc\" + 0.009*\"bien\" '\n",
      "  '+ 0.009*\"plus\" + 0.009*\"meme\" + 0.009*\"tout\" + 0.009*\"aller\" + '\n",
      "  '0.009*\"falloir\"'),\n",
      " (4,\n",
      "  '0.149*\"femme\" + 0.045*\"armee\" + 0.030*\"homme\" + 0.017*\"chef\" + '\n",
      "  '0.016*\"combat\" + 0.012*\"aussi\" + 0.010*\"professionnel\" + 0.009*\"an\" + '\n",
      "  '0.009*\"arme\" + 0.009*\"pourcent\"'),\n",
      " (5,\n",
      "  '0.000*\"faire\" + 0.000*\"dire\" + 0.000*\"plus\" + 0.000*\"aussi\" + 0.000*\"meme\" '\n",
      "  '+ 0.000*\"falloir\" + 0.000*\"donc\" + 0.000*\"peu\" + 0.000*\"aller\" + '\n",
      "  '0.000*\"bien\"'),\n",
      " (6,\n",
      "  '0.000*\"faire\" + 0.000*\"suisse\" + 0.000*\"aller\" + 0.000*\"aussi\" + '\n",
      "  '0.000*\"dire\" + 0.000*\"meme\" + 0.000*\"tout\" + 0.000*\"falloir\" + 0.000*\"plus\" '\n",
      "  '+ 0.000*\"alors\"'),\n",
      " (7,\n",
      "  '0.001*\"sep\" + 0.000*\"copinage\" + 0.000*\"rag\" + 0.000*\"complements\" + '\n",
      "  '0.000*\"avertisseur\" + 0.000*\"discredit\" + 0.000*\"enquete_parlementair\" + '\n",
      "  '0.000*\"honteuse\" + 0.000*\"hargneux\" + 0.000*\"enfantillage\"'),\n",
      " (8,\n",
      "  '0.046*\"media\" + 0.029*\"journal\" + 0.028*\"redevance\" + 0.028*\"information\" + '\n",
      "  '0.026*\"presse\" + 0.024*\"service_public\" + 0.021*\"journaliste\" + '\n",
      "  '0.014*\"public\" + 0.014*\"radio\" + 0.012*\"redaction\"'),\n",
      " (9,\n",
      "  '0.015*\"donc\" + 0.014*\"eter\" + 0.011*\"faire\" + 0.010*\"net\" + 0.010*\"plus\" + '\n",
      "  '0.009*\"tout\" + 0.009*\"dire\" + 0.009*\"aussi\" + 0.009*\"tre\" + 0.009*\"aller\"'),\n",
      " (10,\n",
      "  '0.027*\"faire\" + 0.027*\"oui\" + 0.023*\"aller\" + 0.017*\"alors\" + 0.016*\"donc\" '\n",
      "  '+ 0.015*\"peu\" + 0.014*\"bien\" + 0.012*\"plus\" + 0.011*\"petit\" + 0.011*\"non\"'),\n",
      " (11,\n",
      "  '0.018*\"faire\" + 0.016*\"plus\" + 0.012*\"dire\" + 0.012*\"ville\" + 0.012*\"donc\" '\n",
      "  '+ 0.011*\"aller\" + 0.009*\"canton\" + 0.008*\"initiative\" + 0.008*\"peu\" + '\n",
      "  '0.008*\"aussi\"'),\n",
      " (12,\n",
      "  '0.020*\"plus\" + 0.020*\"faire\" + 0.016*\"donc\" + 0.012*\"aussi\" + '\n",
      "  '0.012*\"falloir\" + 0.010*\"bien\" + 0.010*\"aller\" + 0.010*\"tout\" + '\n",
      "  '0.008*\"dire\" + 0.008*\"tre\"'),\n",
      " (13,\n",
      "  '0.026*\"faire\" + 0.019*\"dire\" + 0.017*\"donc\" + 0.015*\"plus\" + 0.013*\"aussi\" '\n",
      "  '+ 0.010*\"aller\" + 0.010*\"falloir\" + 0.009*\"tre\" + 0.009*\"meme\" + '\n",
      "  '0.009*\"bien\"')]\n"
     ]
    }
   ],
   "source": [
    "optimal_model = model_list[2]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada] *",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
