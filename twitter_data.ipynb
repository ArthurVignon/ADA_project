{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving data from the Twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this part is to gather all possible tweets from major political parties in Switzerland and from the eminent members of those parties. We selected the 6 parties with the most representatives in the Swiss National Council since the last [2019 elections](https://en.wikipedia.org/wiki/2019_Swiss_federal_election) which are the UDC, PS, PLR, Les Verts, PDC and les Verts'libÃ©raux  in our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports. Tweepy is a library to interact easily with the Twitter API via Python.\n",
    "import tweepy \n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get data from the Twitter API, one needs to create a developper account. We initialize the credentials obtained from Twitter below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key_1 = \"92AFPa7uaAAjwxBWTfpzsc9Gc\" \n",
    "consumer_secret_1 = \"i7KDx59hX2nhc1vCRxewAT4woaAVlW2MJ5CddZsCFRKpxzQIw5\"\n",
    "access_key_1 = \"2934954767-JArTI62xesl1Q5VxNXf9Mx0Czeg9vjQ7MqYufGg\"\n",
    "access_secret_1 = \"roWovEouQhFUK7j4MewuHIKiOfKHHeG0o6OzLh5jwPfbX\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We retrieve the Twitter accounts in both languages of the 6 major political parties in Switzerland. Note that all parties except PDC have seperate Twitter accounts for communucation in French and German. PDC does all its' Twitter communication in both languages from the same account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter usernames of the 6 major political parties\n",
    "frenchAccounts = ['UDCch', 'PSSuisse', 'PLR_Suisse', 'LesVertsSuisses', 'vertliberaux']\n",
    "germanAccounts = ['SVPch', 'spschweiz', 'FDP_Liberalen', 'GrueneCH', 'grunliberale']\n",
    "germanAndFrench = ['CVP_PDC']\n",
    "users = frenchAccounts + germanAccounts + germanAndFrench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below gets all tweets from a given list of users. The Twitter API limits us to a hard limit of a maximum of 3200 tweets per user. We try to get as many tweets as possible from each of the accounts. The features we gather are the following: \n",
    "\n",
    "* ``id``: The ID of a tweet \n",
    "* ``timestamp`` : The time the tweet was published\n",
    "* ``partyname`` : The name of the party as defined in the twitter account\n",
    "* ``username`` : The actual unique twitter username \n",
    "* ``tweet_text`` : The content of the tweet\n",
    "* ``all_hashtags`` : A list containing all hashtags included in the tweet\n",
    "* ``all_mentions`` : A list containing all user mentions in the tweet\n",
    "* ``all_urls`` : A list containing all the URLs in the tweet\n",
    "* ``retweet_count`` : The number of retweets of the given tweet\n",
    "* ``favorite_count`` : The number of favorites of the given tweet\n",
    "* ``range`` : The number of characters in the tweet\n",
    "* `lang` : The language of the tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that retrieves the maximum possible number of tweets from given accounts into a csv file.\n",
    "def get_party_tweets(users, consumer_key, consumer_secret, access_key, access_secret):\n",
    "    \n",
    "    # Authenticate to the Twitter API\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_key, access_secret)\n",
    "    api = tweepy.API(auth,  parser=tweepy.parsers.JSONParser()) \n",
    "    \n",
    "    # Open the CSV file to write to.\n",
    "    with open('data/twitter_data/party_tweets.csv', 'w', encoding=\"utf-8\") as file:\n",
    "\n",
    "        w = csv.writer(file)\n",
    "\n",
    "        # write Header row to spreadsheet\n",
    "        w.writerow(['id', 'timestamp', 'partyname', 'username', 'tweet_text', 'all_hashtags', 'all_mentions', 'all_urls', 'retweet_count', 'favorite_count', 'range', 'lang'])\n",
    "        \n",
    "        # iterate over all usernames\n",
    "        for username in users:\n",
    "            # The index i is for the internal page indexing used in the Twitter API\n",
    "            for i in range(18):\n",
    "                # 200 is the maximum number of tweets one can retrieve per page: 200*18 = 3600 (above 3200 just to be sure)\n",
    "                tweets = api.user_timeline(screen_name=username, count = 200, tweet_mode=\"extended\", page = i)\n",
    "                # Write the attributes in the CSV\n",
    "                for tweet in tweets:\n",
    "                    w.writerow([tweet['id'],\n",
    "                                tweet['created_at'],\n",
    "                                tweet['user']['name'],\n",
    "                                tweet['user']['screen_name'], \n",
    "                                tweet['full_text'].replace('\\n',' '),\n",
    "                                [e['text'] for e in tweet['entities']['hashtags']],\n",
    "                                [e['screen_name'] for e in tweet['entities']['user_mentions']],\n",
    "                                [e['expanded_url'] for e in tweet['entities']['urls']],\n",
    "                                tweet['retweet_count'],\n",
    "                                tweet['favorite_count'],\n",
    "                                tweet['display_text_range'][1],\n",
    "                                tweet['lang']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_party_tweets(users, consumer_key_1, consumer_secret_1, access_key_1, access_secret_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the account names for all eminent members of the given parties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS_accounts = ['ChristianLevrat', 'NordmannRoger', 'beat_jans', 'jcschwaab', 'MarinaCarobbio', 'PascaleBruderer', 'SusanneSlo', 'enussbi', 'cedricwermuth', 'PaulRechsteiner', 'BaGysi', 'CarloSommaruga', 'danieljositsch', 'yferi', 'zanettiroberto', 'eviallemann', 'margretkiener', 'JayBadran', 'MathiasReynard', 'ada_marra']\n",
    "PDC_accounts = ['SchmidFederer', 'ybuttet', 'ClaudeBegle', 'LeoMuellerLU', 'MarcoRomanoPPD', 'BulliardMarbach', 'fregazzi', 'Ch_Lohr', 'PirminBischof', 'gerhardpfister', 'lombardi1956', 'GraberKonrad', 'Violapamherd', 'RuthHumbel', 'MullerAltermatt', 'martin_candinas', 'Elisabeth_S_S', 'KathyRiklin', 'DdeBuman', 'engler_stefan']  \n",
    "UDC_accounts = ['thomas_aeschi', 'AdrianAmstutz', 'BrandHeinz', 'jfrime', 'AmaudruzCeline', 'NatalieRickli', 'UGiezendanner', 'verenaherzog', 'SVPBrunner', 'lukasreimann', 'LuziStamm']\n",
    "Les_Verts_accounts = ['bglaettli', 'RobertCramer_GE', 'SibelArslanBS', 'bastiengirod', 'RegulaRytz', 'nr_mayagraf', 'adelethorens', 'Chrige_Haesler', 'FrickerJonas']\n",
    "Les_Verts_liberaux_accounts = ['tiana_moser', 'Martin_Baeumle', 'kathrinbertschy', 'beatflach', 'Juerg_Grossen', 'I_Chevalley']\n",
    "PLR_accounts = ['nantermod', 'OliFrancais', 'CLuscher', 'ChristaMarkwald', 'IsabelleMoret', 'DorisFiala', 'RaphaelComteCE', 'SchneeDani67', 'fderder', 'ThierryBurkart', 'Marcel_Dobler', 'LaurentWehrli', 'Damian_Mueller_', 'FluriKurt', 'ignaziocassis', 'cwasi', 'PetraGoessi', 'RuediNoser']\n",
    "all_member_accounts = PS_accounts + PDC_accounts + UDC_accounts + Les_Verts_accounts + Les_Verts_liberaux_accounts + PLR_accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a helper function for us to identify the party name of the member\n",
    "def get_party_name(username):\n",
    "    if username in PS_accounts:\n",
    "        return 'PS Suisse'\n",
    "    elif username in PDC_accounts:\n",
    "        return 'CVP PDC PPD PCD'\n",
    "    elif username in UDC_accounts:\n",
    "        return 'UDC Suisse'\n",
    "    elif username in Les_Verts_accounts:\n",
    "        return 'Les VERTS suisses ðŸŒ»'\n",
    "    elif username in Les_Verts_liberaux_accounts:\n",
    "        return \"Vert'libÃ©raux Suisse\"\n",
    "    elif username in PLR_accounts:\n",
    "        return 'PLR Suisse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that retrieves the tweets of party members\n",
    "def get_member_tweets(users, consumer_key, consumer_secret, access_key, access_secret, file_name):\n",
    "    \n",
    "    # Authenticate to the Twitter API\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_key, access_secret)\n",
    "    api = tweepy.API(auth,  parser=tweepy.parsers.JSONParser()) \n",
    "    \n",
    "    # Open the CSV file to write to.\n",
    "    with open(file_name, 'w', encoding=\"utf-8\") as file:\n",
    "\n",
    "        w = csv.writer(file)\n",
    "\n",
    "        #write header row to spreadsheet\n",
    "        w.writerow(['id', 'timestamp', 'member_name', 'party_name', 'username', 'tweet_text', 'all_hashtags', 'all_mentions', 'all_urls', 'retweet_count', 'favorite_count', 'range', 'lang'])\n",
    "        \n",
    "        # iterate over all usernames\n",
    "        for username in users:\n",
    "            \n",
    "            # Get the name of the members party\n",
    "            party_name = get_party_name(username)\n",
    "            \n",
    "            for i in range(18):\n",
    "                tweets = api.user_timeline(screen_name=username, count = 200, tweet_mode=\"extended\", page = i)\n",
    "                for tweet in tweets:\n",
    "                    w.writerow([tweet['id'],\n",
    "                                tweet['created_at'],\n",
    "                                tweet['user']['name'],\n",
    "                                party_name,\n",
    "                                tweet['user']['screen_name'], \n",
    "                                tweet['full_text'].replace('\\n',' '),\n",
    "                                [e['text'] for e in tweet['entities']['hashtags']],\n",
    "                                [e['screen_name'] for e in tweet['entities']['user_mentions']],\n",
    "                                [e['expanded_url'] for e in tweet['entities']['urls']],\n",
    "                                tweet['retweet_count'],\n",
    "                                tweet['favorite_count'],\n",
    "                                tweet['display_text_range'][1],\n",
    "                                tweet['lang']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The execution of the next line in order to the tweets of all members gives an error. This is normal since we retreive too many tweets. Twitter has a limit of the number of requests one can send in an hour. We just query with the remainder of the usernames and join the CSV's obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "[{'message': 'Rate limit exceeded', 'code': 88}]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-ee52a2270039>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_member_tweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_member_accounts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsumer_key_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsumer_secret_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccess_key_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccess_secret_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'data/twitter_data/member_tweets.csv'\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-8a8b3c6be3c2>\u001b[0m in \u001b[0;36mget_member_tweets\u001b[1;34m(users, consumer_key, consumer_secret, access_key, access_secret, file_name)\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mparty_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_party_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musername\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                 \u001b[0mtweets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_timeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscreen_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0musername\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtweet_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"extended\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                     w.writerow([tweet['id'],\n",
      "\u001b[1;32mD:\\Users\\ASUS\\Anaconda3\\envs\\ada\\lib\\site-packages\\tweepy\\binder.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\ASUS\\Anaconda3\\envs\\ada\\lib\\site-packages\\tweepy\\binder.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mis_rate_limit_error_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mRateLimitError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mTweepError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapi_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mapi_error_code\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRateLimitError\u001b[0m: [{'message': 'Rate limit exceeded', 'code': 88}]"
     ]
    }
   ],
   "source": [
    "get_member_tweets(all_member_accounts, consumer_key_1, consumer_secret_1, access_key_1, access_secret_1, 'data/twitter_data/member_tweets.csv' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at our CSV file and see that we exceeded the rate limit for the tweets of 'DdeBuman'. We join the rest of the parties accounts to the members of PDC for which the retrieved tweets were incomplete and launch another query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "member_tweets_batch_2 = ['DdeBuman', 'engler_stefan'] + UDC_accounts + Les_Verts_accounts + Les_Verts_liberaux_accounts + PLR_accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_member_tweets(member_tweets_batch_2, consumer_key_1, consumer_secret_1, access_key_1, access_secret_1, 'data/twitter_data/member_tweets_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No error in the execution this time. We got the maximum number of tweets from all the accounts. Now we merge both member tweet files  `member_tweets_2.csv` and `member_tweets_2.csv` into a single one by putting them into a pandas DataFrame and deleting duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv(\"data/twitter_data/member_tweets.csv\")\n",
    "df2=pd.read_csv(\"data/twitter_data/member_tweets_2.csv\")\n",
    "\n",
    "full_df = pd.concat([df1,df2])\n",
    "unique_df = full_df.drop_duplicates(keep='last')\n",
    "unique_df.to_csv('data/twitter_data/merged_member_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we remove the additional CSV files we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove('data/twitter_data/member_tweets.csv')\n",
    "os.remove('data/twitter_data/member_tweets_2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada] *",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
